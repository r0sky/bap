{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, textacy, pickle, re, spacy, flashtext, contractions, unicodedata\n",
    "from dateutil import parser\n",
    "from collections import Counter\n",
    "from textacy import preprocessing, ke, vsm, tm, text_utils, Corpus, doc\n",
    "from flashtext import KeywordProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def striplist(text):\n",
    "    return ([x.strip() for x in text])  # to remove the extra spaces\n",
    "\n",
    "def strip_accents(s):  # strips the accents in Latin languages for example Ã¼ to u\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def rem_nonasc(text):\n",
    "    regex = r'[^\\x00-\\x7f]'\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def rem_jpg(text):\n",
    "    regex = r'[a-zA-Z0-9_.+-]+\\.(jpg|png|JPG|jpeg)'\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def rem_html(text):\n",
    "    regex = r'(?=/).*?(?<=html)'\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def remove_nonlatin(text):\n",
    "    s = (ch for ch in text\n",
    "         if unicodedata.name(ch).startswith(('LATIN', 'DIGIT', 'SPACE')))\n",
    "    return ''.join(text)\n",
    "\n",
    "def rem_html_tags(text):\n",
    "    regex = r'<.*?>'\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def rem_http(text):\n",
    "    regex = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace GB words with US\n",
    "\n",
    "gb2us = pd.read_csv('gb2us.csv', header=None, index_col=0, squeeze=True, encoding='utf8').to_dict() # path of gb2us.csv should be written.\n",
    "gb2us_processor = KeywordProcessor(case_sensitive=False)\n",
    "keyword_dict = []\n",
    "for k, v in gb2us.items():\n",
    "    temp = (str(k), [(v)])\n",
    "    keyword_dict.append(temp)\n",
    "gb2us_dict = dict(keyword_dict)\n",
    "gb2us_processor.add_keywords_from_dict(gb2us_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Customized Cleaning\n",
    "\n",
    "def findBet(sw, ew, text):  # Finds the text between two strings\n",
    "    regex = r\"(?=\" + sw + \").*?(?<=\" + ew + \")\"\n",
    "    w = text.str.findall(regex)\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return [item for sublist in txt for item in sublist]\n",
    "\n",
    "def delBet(sw, ew, text):\n",
    "    regex = r\"(?=\" + sw + \").*?(?<=\" + ew + \")\"\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def kwic(kw, wd, dataframe):  # bunu ew sw ve ew icerecek sekilde duzelt\n",
    "    for news in dataframe:\n",
    "        w = text_utils.KWIC(news, kw, window_width=wd)\n",
    "\n",
    "def listEmail(text):\n",
    "    regex = r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+\"\n",
    "    w = text.str.findall(regex)\n",
    "    xx = list(filter(None, w))\n",
    "    zz = [i for i in w if type(i) is not float]\n",
    "    dct = dict(Counter([item for sublist in zz for item in sublist]))\n",
    "    return [(k, dct[k]) for k in sorted(dct, key=dct.get, reverse=True)]\n",
    "\n",
    "def delEmail(text):\n",
    "    regex = r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+\"\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def listTwt(text):\n",
    "    regex = r'\\s[@|#][a-zA-Z0-9_.+-]+'\n",
    "    w = text.str.findall(regex)\n",
    "    xx = list(filter(None, w))\n",
    "    zz = [i for i in w if type(i) is not float]\n",
    "    dct = dict(Counter([item for sublist in zz for item in sublist]))\n",
    "    return [(k, dct[k]) for k in sorted(dct, key=dct.get, reverse=True)]\n",
    "\n",
    "def delTwt(text):\n",
    "    twtskeep = \"(?!@TicBot|#BeBoldForChange|#MeToo|@nightmare_machine|#TalkingTech|#AlphaGo|@privacyproject)\"\n",
    "    regex =  twtskeep + \"[@|#][a-zA-Z0-9_.+-]+\"\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def listDom(text):\n",
    "    regex = r'\\b\\w+\\.[com|net|org|info]+[\\.[a-z]{2,3}]?'\n",
    "    w = text.str.findall(regex)\n",
    "    xx = list(filter(None, w))\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    dct = dict(Counter([item for sublist in txt for item in sublist]))\n",
    "    return [(k, dct[k]) for k in sorted(dct, key=dct.get, reverse=True)]\n",
    "\n",
    "def delDom(text):\n",
    "    webkeep = r\"(?!\\bAmazon\\b|\\bJD\\b|\\bSalesforce\\b|\\bsohu\\b|\\bGoogle\\b|\\bfacebook\\b|\\bthreadinmotion\\b|\\bmoodnode\\b|\\blinkedin\\b|\\baccenture\\b)\"\n",
    "    regex = webkeep + r\"\\b\\w+\\.[com|net|org|info]+[\\.[a-z]{2,3}]?\"\n",
    "    w = text.str.replace(regex, ' ').str.strip()\n",
    "    txt = [i for i in w if type(i) is not float]\n",
    "    return txt\n",
    "\n",
    "def cleanup(dates):\n",
    "    for date in dates:\n",
    "        try:\n",
    "            yield parser.parse(date, dayfirst=True)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            print(\" {}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viterby algorithm for segmenting accidentally merged words\n",
    "\n",
    "with open(\"C:/Users/asuer/Documents/BAP/text_analysis/gwdict.txt\", \"rb\") as fp:  # Unpickling\n",
    "    dic = pickle.load(fp)\n",
    "\n",
    "def viterbi_segment(tx):\n",
    "    probs, lasts = [1.0], [0]\n",
    "    for i in range(1, len(tx) + 1):\n",
    "        prob_k, k = max((probs[j] * word_prob(tx[j:i]), j)\n",
    "                        for j in range(max(0, i - max_word_length), i))\n",
    "        probs.append(prob_k)\n",
    "        lasts.append(k)\n",
    "    words = []\n",
    "    i = len(tx)\n",
    "    while 0 < i:\n",
    "        words.append(tx[lasts[i]:i])\n",
    "        i = lasts[i]\n",
    "    words.reverse()\n",
    "    return words, probs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_prob(word): return dictionary[word] / total\n",
    "\n",
    "def words(tx): return re.findall('[a-z]+', tx.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = striplist(dic)\n",
    "dictionary = Counter(dic)\n",
    "max_word_length = max(map(len, dictionary))\n",
    "total = float(sum(list(dictionary.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
